{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"The Trading Infrastructure Toolkit for Python  <p>   Research, simulate, and deploy algorithmic strategies \u2014 all in one place. </p>"},{"location":"#quickstart","title":"Quickstart","text":"PipPoetryColab <pre><code>pip install onesecondtrader\n</code></pre> <pre><code>poetry add onesecondtrader\n</code></pre> <pre><code>!pip install onesecondtrader\n</code></pre>"},{"location":"quickstart/","title":"\u2192 Quickstart","text":""},{"location":"quickstart/#redirecting","title":"Redirecting...","text":"<p>If you are not redirected automatically, click here.</p>"},{"location":"api-reference/log_config/","title":"Log Config","text":"<p>Logging configuration for the OneSecondTrader package.</p> <p>This module sets up the default logging configuration and provides a logger instance for use throughout the package.</p> Source code in <code>log_config.py</code> <pre><code>\"\"\"Logging configuration for the OneSecondTrader package.\n\nThis module sets up the default logging configuration and provides\na logger instance for use throughout the package.\n\"\"\"\n\nimport logging\n\n\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format=\"%(asctime)s - %(levelname)s - %(threadName)s - %(message)s\",\n)\n\nlogger = logging.getLogger(\"onesecondtrader\")\n</code></pre>"},{"location":"api-reference/overview/","title":"API Reference","text":"<ul> <li> <p>Log Config </p> <p> View <code>log_config.py</code> API</p> </li> </ul>"},{"location":"documentation/architecture/","title":"Architecture","text":"<p>Under Construction</p> <p>This section is under construction! OneSecondTrader is still a work in progress, but don\u2019t worry \u2013 a pre-release version is just around the corner. Grab a coffee and hang tight!</p>"},{"location":"documentation/architecture/#package-architecture","title":"Package Architecture","text":""},{"location":"documentation/backtesting/","title":"Backtesting","text":"<p>Under Construction</p> <p>This section is under construction! OneSecondTrader is still a work in progress, but don\u2019t worry \u2013 a pre-release version is just around the corner. Grab a coffee and hang tight!</p>"},{"location":"documentation/backtesting/#backtesting-strategies","title":"Backtesting Strategies","text":""},{"location":"documentation/developing/","title":"Package Development","text":""},{"location":"documentation/developing/#continuous-integration-delivery-cicd-pipeline","title":"Continuous Integration &amp; Delivery (CI/CD) Pipeline","text":"<p>This project's continuous integration &amp; continuous delivery (CI/CD) pipeline consists of two distinct workflows:  local pre-commit hooks that run on <code>git commit</code> to ensure code quality,  and GitHub Actions that run on <code>git push origin master</code> to automate releases.</p> <p>In order for the pipeline to work, the following configuration is required:</p> <ul> <li>version field in <code>pyproject.toml</code> must be set to appropriate version <pre><code>[tool.poetry]\nname = \"onesecondtrader\"\nversion = \"0.1.0\"  # Updated automatically by bump_version.py\n</code></pre></li> <li><code>mkdocs.yml</code> must have <code>mkdocstrings-python</code> plugin configured <pre><code>plugins:\n  - mkdocstrings:\n      handlers:\n        python:\n          options:\n            docstring_style: google\n</code></pre></li> </ul>"},{"location":"documentation/developing/#local-pre-commit-workflow","title":"Local Pre-Commit Workflow","text":"<p>To ensure that only good quality code is commited to the repository, a series of pre-commit hooks are executed before each commit.  These hooks include code quality checks, testing, security scans, and automated API reference generation.  This workflow is orchestrated by the <code>pre-commit</code> package, which is configured in the <code>.pre-commit-config.yaml</code> file.  If any of these checks fail, the commit is blocked and the developer must fix the issues before retrying.</p> <p>Prior to usage, the pre-commit hooks must be installed by running: <pre><code>poetry run pre-commit install\npoetry run pre-commit install --hook-type commit-msg\npoetry run pre-commit run --all-files # Optional: Test installation\n</code></pre></p> <p>This project follows Conventional Commits specification for commit messages. This standardized format enables automated semantic versioning and changelog generation. The commit messages must have the following format:</p> <pre><code>&lt;type&gt;: &lt;description&gt;\n\n[optional body]\n\n[optional footer(s)]\n</code></pre> <p>The commit message must start with a type, followed by a colon and a space, and then a description. The type must be one of the following:</p> <ul> <li>feat: New features that add functionality</li> <li>fix: Bug fixes and patches</li> <li>docs: Documentation changes only</li> <li>chore: Maintenance tasks, dependency updates, build changes</li> <li>test: Adding or modifying tests</li> <li>refactor: Code changes that neither fix bugs nor add features</li> <li>perf: Performance improvements</li> <li>ci: Changes to CI/CD configuration</li> </ul> <p>Examples:</p> <pre><code>feat: added trade-by-trade chart generation \n</code></pre> <p>The following diagram illustrates this pre-commit workflow:</p> Local Pre-Commit Workflow <pre><code>---\nconfig:\n  themeVariables:\n    fontSize: \"11px\"\n---\ngraph TD\n    A([&lt;kbd&gt;git commit&lt;/kbd&gt;]) --&gt;|Trigger Pre-commit Workflow on &lt;kbd&gt;commit&lt;/kbd&gt;| PrecommitHooks\n\n    subgraph PrecommitHooks [\"Local Pre-commit Hooks\"]\n        B[\"&lt;b&gt;Code Quality Checks&lt;/b&gt;&lt;br/&gt;\u2022 Ruff Check &amp; Format&lt;br/&gt;\u2022 MyPy Type Checking&lt;br/&gt;\u2022 Tests &amp; Doctests\"]\n        C[\"&lt;b&gt;Security Checks&lt;/b&gt;&lt;br/&gt;\u2022 Bandit &amp; Safety&lt;br/&gt;\u2022 Gitleaks Secret Detection\"]\n        D[\"&lt;b&gt;File Validation&lt;/b&gt;&lt;br/&gt;\u2022 YAML/TOML/JSON Check&lt;br/&gt;\u2022 End-of-file Fixer&lt;br/&gt;\u2022 Large Files Check&lt;br/&gt;\u2022 Merge Conflict Check&lt;br/&gt;\u2022 Debug Statements Check&lt;\"]\n        E[\"&lt;b&gt;Generate API Documentation&lt;/b&gt; via &lt;kbd&gt;scripts/generate_api_docs.py&lt;/kbd&gt;&lt;br/&gt;\u2022 Auto-generate docs&lt;br/&gt;\u2022 Stage changes\"]\n        B --&gt; C --&gt; D --&gt; E\n    end\n\n    F([Write Commit Message])\n    PrecommitHooks --&gt;|Pass| F\n    PrecommitHooks -.-&gt;|Fail| H\n\n    subgraph CommitMessageHook [\"Commit Message Hook\"]\n        G{Commit Message Valid?}\n    end\n        G -.-&gt;|No| H[Commit Blocked]\n        G --&gt;|Yes| I[Commit Successful]\n\n    F --&gt; CommitMessageHook\n\n    H -.-&gt;|Rework &amp; Restage&lt;br/&gt;| K\n\n    K([\"&lt;kbd&gt;git commit --amend&lt;/kbd&gt;\"])\n\n    K -.-&gt; PrecommitHooks\n\n    L([\"&lt;kbd&gt;git pull --rebase origin master&lt;/kbd&gt;\"])\n\n    L -.-&gt;|Rebase &amp; Resolve Conflicts| M\n\n    M([&lt;kbd&gt;git add &lt;...&gt;&lt;/kbd&gt;])\n\n    M -.-&gt; A\n\n    I -.~.-&gt; J([&lt;kbd&gt;git push&lt;/kbd&gt;])</code></pre> Source Code: <code>.pre-commit-config.yaml</code> <pre><code>fail_fast: true\nrepos:\n  - repo: local\n    hooks:\n      - id: ruff-check\n        name: Ruff check\n        entry: poetry run ruff check\n        args: [--fix]\n        language: system\n        types: [file, python]\n\n      - id: ruff-format\n        name: Ruff format\n        entry: poetry run ruff format\n        language: system\n        types: [file, python]\n\n      - id: mypy\n        name: Type check with mypy\n        entry: poetry run mypy src/\n        language: system\n        types: [file, python]\n        pass_filenames: false\n\n      - id: pytest\n        name: Run tests\n        entry: poetry run pytest\n        language: system\n        pass_filenames: false\n\n      - id: doctest\n        name: Run doctests in docstrings\n        entry: poetry run pytest --doctest-modules\n        language: system\n        pass_filenames: false\n\n      - id: bandit\n        name: Bandit security check\n        entry: poetry run bandit -r src/\n        language: system\n        pass_filenames: false\n\n      - id: safety\n        name: Safety security check\n        entry: &gt;\n          bash -c \"poetry export -f requirements.txt --without-hashes | safety check --stdin\"\n        language: system\n        pass_filenames: false\n\n      - id: coverage\n        name: Coverage threshold check\n        entry: poetry run pytest --cov=src/ --cov-fail-under=90\n        language: system\n        pass_filenames: false\n\n      - id: generate-api-docs\n        name: Generate and stage API documentation\n        entry: &gt;\n          bash -c \"poetry run python scripts/generate_api_docs.py &amp;&amp;\n                   git add docs/api-reference/\"\n        language: system\n        pass_filenames: false\n\n  - repo: https://github.com/compilerla/conventional-pre-commit\n    rev: v4.2.0\n    hooks:\n      - id: conventional-pre-commit\n        stages: [commit-msg]\n\n  - repo: https://github.com/gitleaks/gitleaks\n    rev: v8.28.0\n    hooks:\n      - id: gitleaks\n\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v5.0.0\n    hooks:\n      - id: check-yaml\n        exclude: ^mkdocs\\.yml$\n      - id: check-toml\n      - id: check-json\n      - id: end-of-file-fixer\n      - id: debug-statements\n      - id: check-added-large-files\n      - id: check-merge-conflict\n      - id: check-case-conflict\n</code></pre> Source Code: <code>scripts/generate_api_docs.py</code> <pre><code>#!/usr/bin/env python3\nimport logging\nimport shutil\nfrom pathlib import Path\n\nimport yaml\n\n# SETUP LOGGER\n# --------------------------------------------------------------------------------------\n\n\nlogging.basicConfig(\n    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n)\nlogger = logging.getLogger(__name__)\n\n\n# API REFERENCE DOCUMENTATION GENERATION\n# --------------------------------------------------------------------------------------\n\n\ndef generate_api_docs():\n    \"\"\"Generate API reference documentation from docstrings via mkdocstrings package.\n\n    Automatically discovers Python modules in src/onesecondtrader and generates\n    corresponding markdown documentation files. Modules with substantial content\n    (classes/functions) use mkdocstrings for automatic API documentation, while\n    simple modules display their source code directly. This is done in the following\n    steps:\n\n        1. Clean and recreate docs/api-reference directory\n        2. Discover all Python modules (excluding __init__.py)\n        3. Generate individual module documentation pages\n        4. Create overview page with navigation cards\n        5. Update mkdocs.yml navigation structure\n\n    Should modules not contain any substantial content (no classes/functions), their\n    source code is displayed directly in the API reference documentation.\n\n    Output:\n        - Individual .md files for each module in docs/api-reference/\n        - Overview page at docs/api-reference/overview.md\n        - Updated navigation in mkdocs.yml\n\n    Raises:\n        FileNotFoundError: If not run from project root directory.\n\n    Note:\n        This script must be run from the project root directory.\n    \"\"\"\n    logger.info(\"Starting to generate API documentation...\")\n\n    # VALIDATE THAT WE'RE IN THE PROJECT ROOT DIRECTORY\n    # ----------------------------------------------------------------------------------\n\n    src_path = Path(\"src/onesecondtrader\")\n    mkdocs_path = Path(\"mkdocs.yml\")\n\n    if not src_path.exists() or not mkdocs_path.exists():\n        logger.error(\"Script must be run from the project root directory.\")\n        raise FileNotFoundError(\"Script must be run from the project root directory. \")\n\n    # CLEAN AND RECREATE API REFERENCE DOCS DIRECTORY\n    # ----------------------------------------------------------------------------------\n\n    docs_path = Path(\"docs/api-reference\")\n    if docs_path.exists():\n        shutil.rmtree(docs_path)\n        logger.info(f\"Cleaned existing documentation directory: {docs_path}\")\n    docs_path.mkdir(parents=True, exist_ok=True)\n\n    # DISCOVER ALL PYTHON MODULES IN src/onesecondtrader (EXCLUDING __init__.py)\n    # ----------------------------------------------------------------------------------\n\n    modules = []\n    for py_file in src_path.glob(\"*.py\"):\n        if py_file.name != \"__init__.py\":\n            module_name = py_file.stem\n            modules.append(module_name)\n\n    logger.info(f\"Found {len(modules)} modules: {', '.join(modules)}\")\n\n    # GENERATE INDIVIDUAL MODULE DOCUMENTATION PAGES\n    # ----------------------------------------------------------------------------------\n\n    for module in modules:\n        title = module.replace(\"_\", \" \").title()\n\n        # Check if module has substantial content (classes/functions)\n        module_file = src_path / f\"{module}.py\"\n        module_content = module_file.read_text()\n\n        # Simple check for classes or functions\n        has_classes_or_functions = (\n            \"def \" in module_content or \"class \" in module_content\n        )\n\n        if has_classes_or_functions:\n            # Use mkdocstrings for modules with classes/functions\n            md_content = f\"\"\"# {title}\n\n::: onesecondtrader.{module}\n    options:\n      show_root_heading: False\n      show_source: true\n      heading_level: 2\n      show_root_toc_entry: False\n\"\"\"\n        else:\n            # Indent the module content for the admonition\n            indented_content = \"\\n\".join(\n                \"    \" + line for line in module_content.split(\"\\n\")\n            )\n\n            # Manual source code display for simple modules\n            md_content = f\"\"\"# {title}\n\n::: onesecondtrader.{module}\n    options:\n      show_root_heading: False\n      show_source: false\n      heading_level: 2\n      show_root_toc_entry: False\n\n???+ quote \"Source code in `{module}.py`\"\n\n    ```python linenums=\"1\"\n{indented_content}\n    ```\n\"\"\"\n\n        md_file = docs_path / f\"{module}.md\"\n        md_file.write_text(md_content)\n        logger.debug(f\"Generated {md_file}\")\n\n    # GENERATE OVERVIEW PAGE WITH NAVIGATION CARDS\n    # ----------------------------------------------------------------------------------\n\n    overview_content = \"\"\"---\nhide:\n#  - navigation\n#  - toc\n---\n\n# :material-text-box-search-outline: **API** Reference\n\n&lt;div class=\"grid cards\" markdown&gt;\n\n\"\"\"\n\n    for module in sorted(modules):\n        title = module.replace(\"_\", \" \").title()\n\n        overview_content += f\"\"\"\n-   __{title}__&amp;nbsp;&amp;nbsp;\n\n    ---\n\n    [:material-link-variant: View `{module}.py` API]({module}.md)\n\"\"\"\n\n    overview_content += \"\"\"\n&lt;/div&gt;\n\"\"\"\n\n    overview_file = docs_path / \"overview.md\"\n    overview_file.write_text(overview_content)\n    logger.info(f\"Generated {overview_file}\")\n\n    # UPDATE mkdocs.yml NAVIGATION STRUCTURE\n    # ----------------------------------------------------------------------------------\n\n    with open(mkdocs_path) as f:\n        config = yaml.unsafe_load(f)\n\n    # Build API Reference navigation\n    api_nav = [{\"Overview\": \"api-reference/overview.md\"}]\n\n    for module in sorted(modules):\n        title = module.replace(\"_\", \" \").title()\n        api_nav.append({title: f\"api-reference/{module}.md\"})\n\n    # Update navigation - remove existing API Reference and add new one\n    config[\"nav\"] = [\n        item\n        for item in config[\"nav\"]\n        if not (isinstance(item, dict) and \"API Reference\" in item)\n    ]\n    config[\"nav\"].append({\"API Reference\": api_nav})\n\n    # Write updated mkdocs.yml\n    with open(mkdocs_path, \"w\") as f:\n        yaml.dump(config, f, default_flow_style=False, sort_keys=False)\n\n    logger.info(f\"Updated {mkdocs_path}\")\n    logger.info(f\"Success: Generated documentation for {len(modules)} modules\")\n\n\nif __name__ == \"__main__\":\n    generate_api_docs()\n</code></pre>"},{"location":"documentation/developing/#github-actions-workflow","title":"GitHub Actions Workflow","text":"<p>Once a commit is pushed to the remote <code>master</code> branch, the GitHub Actions workflow <code>.github/workflows/release.yml</code> is triggered. Note that the GitHub Actions workflow might push commits to the remote repository.  This means your local branch will be behind the remote branch.</p> <p>In order for this workflow to run properly, two secrets need to be configured (<code>Settings &gt; Secrets and variables &gt; Actions</code>):</p> <ul> <li><code>GH_PAT</code>: Personal Access Token with enhanced permissions (see PAT Setup below)</li> <li><code>PYPI_API_TOKEN</code>: Generate from PyPI account settings</li> </ul> <p>The default <code>GITHUB_TOKEN</code> has limited permissions and cannot trigger subsequent workflow runs or push to protected branches.  The PAT provides the necessary permissions for the automated release process.   The PAT is created as follows:</p> <ol> <li>Go to GitHub Settings &gt; Developer settings &gt; Personal access tokens &gt; Tokens (classic)</li> <li>Click \"Generate new token (classic)\"</li> <li>Set expiration and select these scopes:</li> <li><code>repo</code> (Full control of private repositories)</li> <li><code>workflow</code> (Update GitHub Action workflows)</li> <li>Copy the token and add it as <code>GH_PAT</code> secret in repository settings</li> </ol> <p>Note that GitHub Actions bot must have write permissions to the repository.</p> <p>The following diagram illustrates this GitHub Actions workflow:</p> GitHub Actions Workflow <pre><code>---\nconfig:\n  themeVariables:\n    fontSize: \"11px\"\n---\ngraph TD\n\n    A0(&lt;kdb&gt;git commit&lt;/kbd&gt;)\n\n    A1(&lt;kdb&gt;git commit --amend&lt;/kdb&gt;)\n\n    A(&lt;kbd&gt;git push origin master&lt;/kbd&gt;) --&gt;|Trigger GitHub Actions Workflow on &lt;kbd&gt;push&lt;/kbd&gt;| GitHubActions\n\n    A2(&lt;kbd&gt;git push origin master --force&lt;/kbd&gt;) --&gt;|Trigger GitHub Actions Workflow on &lt;kbd&gt;push&lt;/kbd&gt;| GitHubActions\n\n    A0 -.-&gt;|Trigger Pre-commit Workflow &amp; Commit| A\n    A1 -.-&gt;|Trigger Pre-commit Workflow &amp; Commit| A2\n\n    subgraph GitHubActions [\"GitHub Actions Environment Setup\"]\n        B[\"&lt;b&gt;Checkout Repository&lt;/b&gt;&lt;br/&gt;Retrieve the full repository history on the latest Ubuntu runner\"]\n        C[\"&lt;b&gt;Setup Python Environment&lt;/b&gt;&lt;br/&gt;Configure the required Python version and install Poetry\"]\n        D[\"&lt;b&gt;Install Dependencies&lt;/b&gt;&lt;br/&gt;Install all project dependencies, including development ones\"]\n        B --&gt; C --&gt; D\n    end\n\n    GitHubActions -.-&gt;|Failure&lt;br/&gt;Rework &amp; Restage| A3\n    A3(&lt;kdb&gt;git commit --amend&lt;/kdb&gt;)\n\n    GitHubActions --&gt;|Environment Setup Complete| QualityChecks\n\n    subgraph QualityChecks [\"CI Quality Validation\"]\n        F[\"&lt;b&gt;Ruff Linting&lt;/b&gt;&lt;br/&gt;Validate code style and enforce formatting rules\"]\n        G[\"&lt;b&gt;MyPy Type Checking&lt;/b&gt;&lt;br/&gt;Static type analysis\"]\n        H[\"&lt;b&gt;Test Suite&lt;/b&gt;&lt;br/&gt;Run all automated tests\"]\n        F --&gt; G --&gt; H\n    end\n\n    QualityChecks -.-&gt;|Failure&lt;br/&gt;Rework &amp; Restage| A3\n\n    QualityChecks --&gt;|CI Quality Checks Passed| GitConfig\n\n    subgraph GitConfig [\"Git Configuration\"]\n        J[\"&lt;b&gt;Configure Git Identity&lt;/b&gt;&lt;br/&gt;Set the automated commit author for CI operations\"]\n        K[\"&lt;b&gt;Setup Authentication&lt;/b&gt;&lt;br/&gt;Enable secure access to the repository with release permissions (requires &lt;kbd&gt;GH_PAT&lt;/kbd&gt;)\"]\n        J --&gt; K\n    end\n\n    GitConfig --&gt;|Git Configured| VersionAnalysis\n\n    subgraph VersionAnalysis [\"Semantic Version Analysis\"]\n        N[\"&lt;b&gt;Execute bump_version.py&lt;/b&gt;&lt;br/&gt;Analyze commits since last tag to decide on version bump and bump level\"]\n        P{Version Bump Required?}\n        N --&gt; P\n    end\n\n    VersionAnalysis --&gt;|No Version Change&lt;br/&gt;Skip Release Process| DocDeployment\n    VersionAnalysis --&gt;|Version Bump Required| ReleaseProcess\n\n\n    subgraph ReleaseProcess [\"Release &amp; Publishing\"]\n        R[\"&lt;b&gt;Update Version &amp; Changelog&lt;/b&gt;&lt;br/&gt;Write new version and regenerate release notes.\"]\n        S[\"&lt;b&gt;Commit &amp; Push&lt;/b&gt;&lt;br/&gt;Commit updated files and push to the default branch.\"]\n        T[\"&lt;b&gt;Publish to PyPI&lt;/b&gt;&lt;br/&gt;Build and upload distributions in one step.\"]\n        U[\"&lt;b&gt;Create GitHub Release&lt;/b&gt;&lt;br/&gt;Publish tag and attach changelog.\"]\n        R --&gt; S --&gt; T --&gt; U\n    end\n\n\n    ReleaseProcess --&gt;|Release Complete| DocDeployment \n\n    subgraph DocDeployment [\"Documentation Deployment\"]\n        X[\"&lt;b&gt;Generate API Documentation&lt;/b&gt;&lt;br/&gt;Automatically build API docs and update navigation\"]\n        Y[\"&lt;b&gt;Install Package for Docs&lt;/b&gt;&lt;br/&gt;Prepare project for import-based documentation\"]\n        Z[\"&lt;b&gt;Deploy to GitHub Pages&lt;/b&gt;&lt;br/&gt;Publish updated documentation site\"]\n        X --&gt; Y --&gt; Z\n    end</code></pre> Source Code: <code>.github/workflows/release.yml</code> <pre><code>name: Release\n\non:\n  push:\n    branches: [master]\n\njobs:\n  release:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - uses: actions/setup-python@v4\n        with:\n          python-version: \"3.11\"\n\n      - name: Install Poetry\n        run: pip install poetry\n\n      - name: Install project dependencies\n        run: poetry install --with dev\n\n      - name: Run Ruff\n        run: poetry run ruff check .\n\n      - name: Run Mypy\n        run: poetry run mypy src/\n\n      - name: Run Tests\n        run: poetry run pytest\n\n      - name: Configure Git\n        run: |\n          git config user.name \"github-actions[bot]\"\n          git config user.email \"github-actions[bot]@users.noreply.github.com\"\n          git remote set-url origin https://x-access-token:${{ secrets.GH_PAT }}@github.com/${{ github.repository }}\n\n      - name: Determine new version and update pyproject.toml\n        id: versioning\n        run: |\n          pip install toml\n          VERSION=$(python scripts/bump_version.py)\n          echo \"version=$VERSION\" &gt;&gt; $GITHUB_OUTPUT\n        env:\n          GH_TOKEN: ${{ secrets.GH_PAT }}\n\n      - name: Commit version bump and changelog if version updated\n        if: steps.versioning.outputs.version != ''\n        run: |\n          git add pyproject.toml CHANGELOG.md\n          git commit -m \"chore(ci): release ${{ steps.versioning.outputs.version }}\"\n          git push origin master\n\n      - name: Build and publish to PyPI\n        if: steps.versioning.outputs.version != ''\n        run: |\n          poetry build\n          poetry publish --username __token__ --password ${{ secrets.PYPI_API_TOKEN }}\n\n      - name: Create GitHub Release\n        if: steps.versioning.outputs.version != ''\n        uses: softprops/action-gh-release@v2\n        with:\n          tag_name: v${{ steps.versioning.outputs.version }}\n          name: v${{ steps.versioning.outputs.version }}\n          body_path: CHANGELOG.md\n\n        env:\n          GITHUB_TOKEN: ${{ secrets.GH_PAT }}\n\n      - name: Generate API documentation\n        run: poetry run python scripts/generate_api_docs.py\n\n      - name: Install package for documentation\n        run: poetry run pip install -e .\n\n      - name: Deploy Documentation\n        run: |\n          git fetch origin\n          poetry run mkdocs gh-deploy --force\n</code></pre> Source Code: <code>scripts/bump_version.py</code> <pre><code>import re\nimport subprocess\nfrom pathlib import Path\n\nPYPROJECT_PATH = Path(\"pyproject.toml\")\nCHANGELOG_PATH = Path(\"CHANGELOG.md\")\n\n\ndef get_commit_messages():\n    try:\n        result = subprocess.run(\n            [\"git\", \"describe\", \"--tags\", \"--abbrev=0\"],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.DEVNULL,\n            text=True,\n            check=True,\n        )\n        latest_tag = result.stdout.strip()\n    except subprocess.CalledProcessError:\n        latest_tag = \"\"\n\n    if latest_tag:\n        cmd = [\"git\", \"log\", \"--pretty=format:%s\", f\"{latest_tag}..HEAD\"]\n    else:\n        cmd = [\"git\", \"log\", \"--pretty=format:%s\"]\n\n    result = subprocess.run(\n        cmd,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        text=True,\n        check=True,\n    )\n    return result.stdout.splitlines()\n\n\ndef determine_bump_level(messages):\n    bump = None\n    for msg in messages:\n        if \"BREAKING CHANGE\" in msg:\n            return \"major\"\n        if msg.startswith(\"feat\"):\n            bump = \"minor\"\n        if msg.startswith(\"fix\") and bump != \"minor\":\n            bump = \"patch\"\n    return bump\n\n\ndef bump_version(current, level):\n    major, minor, patch = map(int, current.split(\".\"))\n    if level == \"major\":\n        major += 1\n        minor = 0\n        patch = 0\n    elif level == \"minor\":\n        minor += 1\n        patch = 0\n    elif level == \"patch\":\n        patch += 1\n    return f\"{major}.{minor}.{patch}\"\n\n\ndef read_current_version():\n    content = PYPROJECT_PATH.read_text()\n    match = re.search(r'version\\s*=\\s*\"(\\d+\\.\\d+\\.\\d+)\"', content)\n    return match.group(1) if match else None\n\n\ndef update_pyproject(new_version):\n    content = PYPROJECT_PATH.read_text()\n    updated = re.sub(\n        r'version\\s*=\\s*\"\\d+\\.\\d+\\.\\d+\"',\n        f'version = \"{new_version}\"',\n        content,\n    )\n    PYPROJECT_PATH.write_text(updated)\n\n\ndef update_changelog(new_version, messages):\n    lines = [f\"## v{new_version}\\n\"]\n    for msg in messages:\n        lines.append(f\"- {msg}\\n\")\n    lines.append(\"\\n\")\n    if CHANGELOG_PATH.exists():\n        lines.append(CHANGELOG_PATH.read_text())\n    CHANGELOG_PATH.write_text(\"\".join(lines))\n\n\ndef main():\n    current = read_current_version()\n    if not current:\n        return\n\n    messages = get_commit_messages()\n    if not messages:\n        return\n\n    level = determine_bump_level(messages)\n    if not level:  # No version bump needed\n        return\n\n    new_version = bump_version(current, level)\n\n    update_pyproject(new_version)\n    update_changelog(new_version, messages)\n\n    print(new_version)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"documentation/overview/","title":"Package Documentation","text":"<ul> <li> <p> Package Architecture </p> <p> View Architecture Documentation Page</p> </li> <li> <p> Backtesting Strategies </p> <p> View Backtesting Documentation Page</p> </li> <li> <p> Live Trading </p> <p> View Trading Documentation Page </p> </li> <li> <p> Package Development </p> <p> View Developing Documentation Page</p> </li> </ul>"},{"location":"documentation/trading/","title":"Trading","text":"<p>Under Construction</p> <p>This section is under construction! OneSecondTrader is still a work in progress, but don\u2019t worry \u2013 a pre-release version is just around the corner. Grab a coffee and hang tight!</p>"},{"location":"documentation/trading/#live-trading","title":"Live Trading","text":""}]}